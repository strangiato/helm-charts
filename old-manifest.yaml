---
# Source: mlflow-server/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: mlflow-server
  labels:
    helm.sh/chart: mlflow-server-0.6.6
    app.kubernetes.io/name: mlflow-server
    app.kubernetes.io/instance: mlflow-server
    app.kubernetes.io/version: "2.12"
    app.kubernetes.io/managed-by: Helm
  annotations:
    serviceaccounts.openshift.io/oauth-redirectreference.primary: '{"kind":"OAuthRedirectReference","apiVersion":"v1","reference":{"kind":"Route","name":"mlflow-server"}}'
---
# Source: mlflow-server/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: mlflow-server
  annotations:
     service.alpha.openshift.io/serving-cert-secret-name: mlflow-server-tls
  labels:
    helm.sh/chart: mlflow-server-0.6.6
    app.kubernetes.io/name: mlflow-server
    app.kubernetes.io/instance: mlflow-server
    app.kubernetes.io/version: "2.12"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: mlflow-server
      protocol: TCP
      name: mlflow-server
    - port: 8443
      targetPort: oauth-proxy
      protocol: TCP
      name: oauth
  selector:
    app.kubernetes.io/name: mlflow-server
    app.kubernetes.io/instance: mlflow-server
---
# Source: mlflow-server/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mlflow-server
  annotations:
    app.openshift.io/vcs-uri: github.com/strangiato/mlflow-server
  labels:
    helm.sh/chart: mlflow-server-0.6.6
    app.kubernetes.io/name: mlflow-server
    app.kubernetes.io/instance: mlflow-server
    app.kubernetes.io/version: "2.12"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: mlflow-server
      app.kubernetes.io/instance: mlflow-server
  template:
    metadata:
      labels:
        app.kubernetes.io/name: mlflow-server
        app.kubernetes.io/instance: mlflow-server
    spec:
      serviceAccountName: mlflow-server
      securityContext:
        {}
      containers:
        - name: mlflow-server
          securityContext:
            {}
          image: "quay.io/troyer/mlflow-server:2.12"
          imagePullPolicy: IfNotPresent
          ports:
            - name: mlflow-server
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /health
              port: mlflow-server
          readinessProbe:
            httpGet:
              path: /health
              port: mlflow-server
            initialDelaySeconds: 30
          env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: mlflow-server
                  key: AWS_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: mlflow-server
                  key: AWS_SECRET_ACCESS_KEY
            - name: MLFLOW_S3_BUCKET_NAME
              valueFrom:
                configMapKeyRef:
                  name: mlflow-server
                  key: BUCKET_NAME
            
            - name: BUCKET_HOST
              valueFrom:
                configMapKeyRef:
                  name: mlflow-server
                  key: BUCKET_HOST
            - name: BUCKET_PORT
              valueFrom:
                configMapKeyRef:
                  name: mlflow-server
                  key: BUCKET_PORT
            - name: MLFLOW_S3_ENDPOINT_URL
              value: 'https://$(BUCKET_HOST):$(BUCKET_PORT)'
            
            
            - name: AWS_CA_BUNDLE
              value: /run/secrets/kubernetes.io/serviceaccount/service-ca.crt
            
            
            - name: PGBOUNCE_HOST
              valueFrom:
                secretKeyRef:
                  name: mlflow-server-pguser-mlflow-server
                  key: pgbouncer-host
            - name: PGBOUNCE_PORT
              valueFrom:
                secretKeyRef:
                  name: mlflow-server-pguser-mlflow-server
                  key: pgbouncer-port
            - name: MLFLOW_DATABASE_HOST
              value: $(PGBOUNCE_HOST):$(PGBOUNCE_PORT)
            - name: MLFLOW_DATABASE_NAME
              valueFrom:
                secretKeyRef:
                  name: mlflow-server-pguser-mlflow-server
                  key: dbname
            - name: MLFLOW_DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mlflow-server-pguser-mlflow-server
                  key: password
            - name: MLFLOW_DATABASE_USERNAME
              valueFrom:
                secretKeyRef:
                  name: mlflow-server-pguser-mlflow-server
                  key: user
            - name: MLFLOW_PORT
              value: '8080'
          resources:
            {}
        - name: oauth-proxy
          image: "registry.redhat.io/openshift4/ose-oauth-proxy:v4.12"
          imagePullPolicy: 
          ports:
            - containerPort: 8443
              name: oauth-proxy
          args:
            - --https-address=:8443
            - --provider=openshift
            - --openshift-sar={"namespace":"mflow-test","resource":"services","resourceName":"mlflow-server","verb":"get"}
            - --openshift-service-account=mlflow-server
            - --upstream=http://localhost:8080
            - --tls-cert=/etc/tls/private/tls.crt
            - --tls-key=/etc/tls/private/tls.key
            - --cookie-secret=SECRET
          volumeMounts:
            - mountPath: /etc/tls/private
              name: oauth-tls
          livenessProbe:
            httpGet:
              path: /oauth/healthz
              port: 8443
              scheme: HTTPS
          readinessProbe:
            httpGet:
              path: /oauth/healthz
              port: 8443
              scheme: HTTPS
          resources:
            {}
      volumes:
        - name: oauth-tls
          secret:
            secretName: mlflow-server-tls
---
# Source: mlflow-server/templates/objectbucketclaim.yaml
apiVersion: objectbucket.io/v1alpha1
kind: ObjectBucketClaim
metadata:
  name: mlflow-server
  labels:
    helm.sh/chart: mlflow-server-0.6.6
    app.kubernetes.io/name: mlflow-server
    app.kubernetes.io/instance: mlflow-server
    app.kubernetes.io/version: "2.12"
    app.kubernetes.io/managed-by: Helm
spec:
  additionalConfig:
    bucketclass: noobaa-default-bucket-class
  generateBucketName: mlflow-server
  storageClassName: openshift-storage.noobaa.io
---
# Source: mlflow-server/charts/postgrescluster/templates/postgres.yaml
apiVersion: postgres-operator.crunchydata.com/v1beta1
kind: PostgresCluster
metadata:
  name: mlflow-server
spec:
  postgresVersion: 14
  instances:
    - name: "instance1"
      replicas: 2
      dataVolumeClaimSpec:
        accessModes:
        - "ReadWriteOnce"
        resources:
          requests:
            storage: "1Gi"
  backups:
    pgbackrest:
      repos:
      - name: repo1
        volume:
          volumeClaimSpec:
            accessModes:
            - "ReadWriteOnce"
            resources:
              requests:
                storage: "1Gi"
  proxy:
    pgBouncer:
      replicas: 2
  openshift: true
---
# Source: mlflow-server/templates/route.yaml
kind: Route
apiVersion: route.openshift.io/v1
metadata:
  name: mlflow-server
  labels:
    helm.sh/chart: mlflow-server-0.6.6
    app.kubernetes.io/name: mlflow-server
    app.kubernetes.io/instance: mlflow-server
    app.kubernetes.io/version: "2.12"
    app.kubernetes.io/managed-by: Helm
spec:
  to:
    kind: Service
    name: mlflow-server
    weight: 100
  port:
    targetPort: oauth
  tls:
    termination: reencrypt
    insecureEdgeTerminationPolicy: Redirect
  wildcardPolicy: None
---
# Source: mlflow-server/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "mlflow-server-test-connection"
  labels:
    helm.sh/chart: mlflow-server-0.6.6
    app.kubernetes.io/name: mlflow-server
    app.kubernetes.io/instance: mlflow-server
    app.kubernetes.io/version: "2.12"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['mlflow-server:8080']
  restartPolicy: Never
---
# Source: mlflow-server/templates/tests/test-training.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "mlflow-server-test-training"
  labels:
    helm.sh/chart: mlflow-server-0.6.6
    app.kubernetes.io/name: mlflow-server
    app.kubernetes.io/instance: mlflow-server
    app.kubernetes.io/version: "2.12"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: training
      image: "quay.io/troyer/mlflow-server-training-test:latest"
      imagePullPolicy: "IfNotPresent"
      env:
        - name: MLFLOW_TRACKING_URI
          value: 'http://mlflow-server:8080'
        - name: MLFLOW_EXPERIMENT
          value: helm-test
  restartPolicy: Never
  serviceAccountName: mlflow-server
